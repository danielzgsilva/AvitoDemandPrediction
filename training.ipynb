{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18, resnet34\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = os.path.join(os.getcwd(), 'datasets')\n",
    "image_root = os.path.join(data_root, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading original and engineered features\n",
    "engineered_features = pd.read_csv(os.path.join(data_root, 'engineered_features.csv'))\n",
    "train_orig = pd.read_csv(os.path.join(data_root, 'train.csv'))\n",
    "test_orig = pd.read_csv(os.path.join(data_root, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_orig.merge(engineered_features, on='user_id', how='left')\n",
    "test_df = test_orig.merge(engineered_features, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wont need these columns\n",
    "train_df = train_df.drop(['item_id', 'user_id'], axis=1)\n",
    "test_df = test_df.drop(['item_id', 'user_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_cols = list(engineered_features.columns)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = [\n",
    "    'image_top_1', 'param_1', 'param_2', 'param_3', \n",
    "    'city', 'region', 'category_name', 'parent_category_name', 'user_type'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df, agg_cols, categories):\n",
    "    \"\"\"Creates some additional features and extracts text features from an ad dataset\"\"\"\n",
    "    \n",
    "    # Fill missing values\n",
    "    df['description'].fillna('unknowndescription', inplace=True)\n",
    "    df['title'].fillna('unknowntitle', inplace=True)\n",
    "    \n",
    "    df['price'].fillna(df['price'].mean(), inplace=True)\n",
    "    df['image'].fillna('noimage', inplace=True)\n",
    "    \n",
    "    for col in agg_cols:\n",
    "        df[col].fillna(-1, inplace=True)\n",
    "        \n",
    "    for col in categorical:\n",
    "        df.loc[:, col] = df[col].fillna('').astype(str)\n",
    "    \n",
    "    # Engineer weekday feature\n",
    "    df['weekday'] = pd.to_datetime(df['activation_date']).dt.day.fillna(0)\n",
    "    df['month_num'] = pd.to_datetime(df['activation_date']).dt.day.fillna(0)\n",
    "    df.drop(['activation_date'], axis=1, inplace=True)\n",
    "    \n",
    "    # Count number of words and unique words in text fields\n",
    "    for col in ['description', 'title']:\n",
    "        df['num_words_' + col] = df[col].apply(lambda comment: len(comment.split())).fillna(0)\n",
    "        df['num_unique_words_' + col] = df[col].apply(lambda comment: \n",
    "                                                      len(set(w for w in comment.split()))).fillna(0)\n",
    "    \n",
    "    # Compute ratio  of words to unique words\n",
    "    df['words_vs_unique_title'] = (df['num_unique_words_title'] / \n",
    "                                   df['num_words_title'] * 100).fillna(0)\n",
    "    df['words_vs_unique_description'] = (df['num_unique_words_description'] / \n",
    "                                         df['num_words_description'] * 100).fillna(0)\n",
    "    \n",
    "    # TF-IDF for title and description\n",
    "    title_vectorizer = CountVectorizer(stop_words=stopwords.words('russian'), lowercase=True)\n",
    "    \n",
    "    desc_vectorizer = TfidfVectorizer(stop_words=stopwords.words('russian'), \n",
    "                                            lowercase=True, ngram_range=(1, 2),\n",
    "                                            max_features=15000)\n",
    "    \n",
    "    title_vecs = title_vectorizer.fit_transform(df['title'])\n",
    "    desc_vecs = desc_vectorizer.fit_transform(df['description'])\n",
    "\n",
    "    title_vecs = pd.DataFrame(title_vecs.todense(), columns=title_vectorizer.get_feature_names())\n",
    "    desc_vecs = pd.DataFrame(desc_vecs.todense(), columns=desc_vectorizer.get_feature_names())\n",
    "    \n",
    "    # one hot encoding\n",
    "    encoder = OneHotEncoder(drop='first')\n",
    "    \n",
    "    encoded_vecs = encoder.fit_transform(df[categories + ['weekday', 'month_num']])\n",
    "    encoded_vecs = pd.DataFrame(encoded_vecs.todense(), columns=encoder.get_feature_names())\n",
    "    \n",
    "    df.drop(categories+['description', 'title'], axis=1, inplace=True)\n",
    "    \n",
    "    # Concanenate textual and tabular features\n",
    "    df = pd.concat([df, title_vecs, desc_vecs, encoded_vecs], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len(train_df)\n",
    "test_len = len(test_df)\n",
    "\n",
    "deal_probs = train_df['deal_probability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate training and testing set prior to computing textual features\n",
    "total_df = pd.concat([train_df.drop(['deal_probability'], axis=1), test_df]).reset_index()\n",
    "\n",
    "# Engineer tabular and textual features\n",
    "total_df = transform(total_df,agg_cols, categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract training and testing set after engineering features\n",
    "train_df = total_df.iloc[:train_len, :].copy()\n",
    "train_df['deal_probability'] = deal_probs\n",
    "test_df = total_df.iloc[test_len:, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(train_df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 4423)\n",
      "(5, 4423)\n",
      "(50, 4422)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape) \n",
    "print(valid_df.shape) \n",
    "print(test_df.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvitoDataset(Dataset):\n",
    "    \"\"\"Avito Torch dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, df, data_dir, image_dir, image_feature_extractor, transform=None, testing=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        df = df.reset_index()\n",
    "        self.images = df['image']\n",
    "        \n",
    "        self.testing = testing\n",
    "        if not testing:\n",
    "            self.deal_probs = df['deal_probability']\n",
    "            \n",
    "        if testing:\n",
    "            self.features = df.drop(['image'], axis=1)\n",
    "        else:\n",
    "            self.features = df.drop(['deal_probability', 'image'], axis=1)\n",
    "        \n",
    "        self.data_dir = data_dir\n",
    "        self.image_dir = image_dir\n",
    "        \n",
    "        self.image_feature_extractor = image_feature_extractor\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_name = os.path.join(self.image_dir, self.images[idx]) + '.jpg'\n",
    "        \n",
    "        if self.images[idx] == 'noimage':\n",
    "            image = None\n",
    "        else:\n",
    "            image = Image.open(img_name)\n",
    "       \n",
    "        features = torch.tensor(self.features.iloc[idx])\n",
    "        \n",
    "        gt = torch.tensor(0).unsqueeze(0)\n",
    "        if not self.testing:\n",
    "            gt = torch.tensor(self.deal_probs[idx]).unsqueeze(0)\n",
    "        \n",
    "        if self.transform and image:\n",
    "            image = self.transform(image).unsqueeze(0)\n",
    "            \n",
    "            # Extract 1000 ResNet image features \n",
    "            image_features = image_feature_extractor(image).squeeze(0)\n",
    "            \n",
    "            # concatenate these to the tabular and text features\n",
    "            features = torch.cat((features, image_features), dim = 0)\n",
    "        else:\n",
    "            features = torch.cat((features, torch.zeros(1000)), dim = 0)\n",
    "        \n",
    "        return features, gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_workers = 8\n",
    "\n",
    "# Resize each image to 224x 224 for resnet\n",
    "input_size = (224, 224)\n",
    "\n",
    "# Tabular and text features, minus the deal prob, plus the 100 image features from ResNet\n",
    "num_features = train_df.shape[1] - 1 + 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_transforms = transforms.Compose([transforms.Resize(input_size),\n",
    "                                       transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetExtractor(nn.Module):\n",
    "    \"\"\"Pretrained ResNet model that will extract image features\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ResNetExtractor, self).__init__()\n",
    "\n",
    "        resnet = resnet34(pretrained = True)\n",
    "        \n",
    "        # Freeze the entire pretrained network\n",
    "        for layer in resnet.parameters():\n",
    "            layer.requires_grad = False\n",
    "            \n",
    "        self.feature_extraction = resnet\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extraction(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetExtractor(\n",
       "  (feature_extraction): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_feature_extractor = ResNetExtractor()\n",
    "image_feature_extractor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = AvitoDataset(train_df, data_root, image_root, image_feature_extractor, torch_transforms)\n",
    "valid = AvitoDataset(valid_df, data_root, image_root, image_feature_extractor, torch_transforms)\n",
    "\n",
    "datasets = {'Train': train, 'Validation': valid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: DataLoader(datasets[x], batch_size=batch_size, shuffle=True, num_workers = num_workers)\n",
    "              for x in ['Train', 'Validation']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    \"\"\"Nueral net that takes tabular, text, and image features and predicts deal probability \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Linear(num_features, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.block2 =  nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        # Mimic the second block here, except have this block extract 128 features\n",
    "        self.fc =  nn.Linear(512, 1)\n",
    "        self.sigmoid = torch.sigmoid\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (block1): Sequential(\n",
       "    (0): Linear(in_features=5422, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NN()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "epochs = 10\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(epoch, model, dataloaders, device, phase):\n",
    "    running_loss = 0.0\n",
    "    running_rmse = 0.0\n",
    "\n",
    "    if phase == 'Train':\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    # Looping through batches\n",
    "    for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "    \n",
    "        # ensures we're doing this calculation on our GPU if possible\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Calculate gradients only if we're in the training phase\n",
    "        with torch.set_grad_enabled(phase == 'Train'):\n",
    "      \n",
    "            # This calls the forward() function on a batch of inputs\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Calculate the loss of the batch\n",
    "            loss = criterion(outputs, labels)\n",
    "            rmse = np.sqrt(loss.item())\n",
    "\n",
    "            # Adjust weights through backpropagation if we're in training phase\n",
    "            if phase == 'Train':\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Document statistics for the batch\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_rmse += rmse * inputs.size(0)\n",
    "    \n",
    "    # Calculate epoch statistics\n",
    "    epoch_loss = running_loss / datasets[phase].__len__()\n",
    "    epoch_acc = running_rmse / datasets[phase].__len__()\n",
    "\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, num_epochs, dataloaders, device):\n",
    "    start = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    print('| Epoch\\t | Train Loss\\t| Train Acc\\t| Valid Loss\\t| Valid Acc\\t| Epoch Time |')\n",
    "    print('-' * 86)\n",
    "    \n",
    "    # Iterate through epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        epoch_start = time.time()\n",
    "       \n",
    "        # Training phase\n",
    "        train_loss, train_acc = run_epoch(epoch, model, dataloaders, device, 'Train')\n",
    "        \n",
    "        # Validation phase\n",
    "        val_loss, val_acc = run_epoch(epoch, model, dataloaders, device, 'Validation')\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "           \n",
    "        # Print statistics after the validation phase\n",
    "        print(\"| {}\\t | {:.4f}\\t| {:.4f}\\t| {:.4f}\\t| {:.4f}\\t| {:.0f}m {:.0f}s     |\"\n",
    "                      .format(epoch + 1, train_loss, train_acc, val_loss, val_acc, \n",
    "                              epoch_time // 60, epoch_time % 60))\n",
    "\n",
    "        # Copy and save the model's weights if it has the best accuracy thus far\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = model.state_dict()\n",
    "\n",
    "    total_time = time.time() - start\n",
    "    \n",
    "    print('-' * 74)\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(total_time // 60, total_time % 60))\n",
    "    print('Best validation RMSE: {:.4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights and return them\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch\t | Train Loss\t| Train Acc\t| Valid Loss\t| Valid Acc\t| Epoch Time |\n",
      "--------------------------------------------------------------------------------------\n",
      "| 1\t | 0.2026\t| 0.4500\t| 0.2445\t| 0.4945\t| 0m 17s     |\n",
      "| 2\t | 0.1879\t| 0.4335\t| 0.2462\t| 0.4962\t| 0m 17s     |\n",
      "| 3\t | 0.2067\t| 0.4546\t| 0.2447\t| 0.4947\t| 0m 17s     |\n",
      "| 4\t | 0.1783\t| 0.4223\t| 0.2420\t| 0.4919\t| 0m 17s     |\n",
      "| 5\t | 0.1861\t| 0.4310\t| 0.2420\t| 0.4919\t| 0m 17s     |\n",
      "| 6\t | 0.1737\t| 0.4167\t| 0.2460\t| 0.4960\t| 0m 18s     |\n",
      "| 7\t | 0.2037\t| 0.4510\t| 0.2485\t| 0.4985\t| 0m 21s     |\n",
      "| 8\t | 0.2082\t| 0.4554\t| 0.2459\t| 0.4959\t| 0m 18s     |\n",
      "| 9\t | 0.1703\t| 0.4110\t| 0.2452\t| 0.4952\t| 0m 17s     |\n",
      "| 10\t | 0.1777\t| 0.4192\t| 0.2476\t| 0.4976\t| 0m 17s     |\n",
      "--------------------------------------------------------------------------\n",
      "Training complete in 2m 57s\n",
      "Best validation RMSE: 0.4985\n"
     ]
    }
   ],
   "source": [
    "model = train(model, criterion, optimizer, epochs, dataloaders, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = AvitoDataset(test_df, data_root, image_root, image_feature_extractor, torch_transforms, testing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test, batch_size=1, shuffle=False, num_workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, device):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs[0].item())\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = test(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.read_csv(os.path.join(data_root, 'sample_submission.csv'))\n",
    "subm['deal_probability'] = preds\n",
    "subm.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
